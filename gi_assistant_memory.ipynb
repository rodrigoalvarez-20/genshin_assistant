{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba5ba5-2f31-4842-b4bf-3e616919cb57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import ElasticVectorSearch\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
    "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from langchain.document_loaders import TextLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b633312-33bf-4044-ab1a-22615531c3ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HF_SENTENCE_TRANSFORMER_MODEL = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "ELASTIC_URL = \"http://localhost:9200/\"\n",
    "MONGO_URL = \"http://localhost:27017/\"\n",
    "ELASTIC_INDEX = \"genshinpedia_small\"\n",
    "DB_FILES = \"en_datasets\"\n",
    "CACHE_DIR = \"./cache\"\n",
    "T2T_MODEL = \"google/flan-t5-base\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17be8782-facb-40c9-80a1-10d3bf4f1113",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_sentences_hf_model():\n",
    "    print(\"Preparing Huggingface embedding setup...\")\n",
    "    return HuggingFaceEmbeddings(model_name=HF_SENTENCE_TRANSFORMER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f152a070-b3b5-400c-861b-62fa9920fccb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creacion del modelo para generacion de texto\n",
    "def get_t5_model():\n",
    "    print(\"Preparing model {}\".format(T2T_MODEL))\n",
    "    tokenizer = AutoTokenizer.from_pretrained(T2T_MODEL)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(T2T_MODEL, cache_dir=CACHE_DIR) \n",
    "    pipe = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=model, \n",
    "        tokenizer=tokenizer, \n",
    "        max_length=100\n",
    "    )\n",
    "    llm = HuggingFacePipeline(pipeline=pipe)\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e88588-2887-4629-98eb-56c8b28005d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "elastic_db = ElasticVectorSearch(embedding=load_sentences_hf_model(), \n",
    "                                 elasticsearch_url=ELASTIC_URL,\n",
    "                                 index_name=ELASTIC_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6740e-06c6-4141-85c6-fc064f6863d8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ORIGINAL_PROMPT = \"\"\"\n",
    "I am a helpful AI that answers questions. When I don't know the answer I say I don't know. \n",
    "I know context: {context} when asked: {question} my response using only information in the context is: \n",
    "\"\"\"\n",
    "TUNED_PROMPT = \"\"\"\n",
    "I am a helpful AI that answers questions providing details from the context in my answer. When I don't know the answer I say \"I don't know\" without the quotes.\n",
    "I know the context: {context} when user ask me the {question}. My detailed response is:\n",
    "\"\"\"\n",
    "\n",
    "MEMORY_PROMPT = \"\"\"\n",
    "I am a helpful AI that answers questions providing details from the context in my answer. When I don't know the answer I say \"I don't know\" without the quotes.\n",
    "I know the context {chat_history} {context} when user asks me {question}, my detailed response is:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f6ef9-a014-4d22-b91d-5691d109371e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_the_llm():\n",
    "    prompt_informed = PromptTemplate(template=TUNED_PROMPT, \n",
    "                                     input_variables=[\"context\", \"question\"])\n",
    "    llm = get_t5_model()\n",
    "    return LLMChain(llm=llm, prompt=prompt_informed, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379ea615-46e1-4706-b7e1-debc2f4a6f65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_memory_llm(memory):\n",
    "    prompt_informed = PromptTemplate(template=MEMORY_PROMPT, \n",
    "                                     input_variables=[\"context\", \"chat_history\", \"question\"])\n",
    "    llm = get_t5_model()\n",
    "    return LLMChain(llm=llm, prompt=prompt_informed, verbose=True, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c589ec-c2da-49f8-a3ab-cc87af7a60b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(memory_key=\"chat_history\",\n",
    "                                  input_key=\"context\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79196e53-41b7-492c-8422-b39cb8ff4dfb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "llm_chain_informed = make_the_llm()\n",
    "#llm_with_memory = make_memory_llm()\n",
    "#llm_with_memory = make_memory_llm(memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd7eb22-e8f2-486e-81b7-8cbf7eb34889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask_a_question(question):\n",
    "    similar_docs = elastic_db.similarity_search(question)\n",
    "    question_context = similar_docs[0].page_content + \"\\n\" + similar_docs[1].page_content\n",
    "    #print(\"Best constructed context: {}\".format(question_context))\n",
    "    ## Ask Local LLM context informed prompt\n",
    "    informed_context = question_context #similar_docs[0].page_content\n",
    "    #informed_response = llm_chain_informed.run(context=informed_context,question=question)\n",
    "    #informed_response = agent_chain.run(context=informed_context, question=question)\n",
    "    informed_response = llm_with_memory.run(context = informed_context, question = question)\n",
    "    \n",
    "    return informed_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa26128f-2bb2-4bca-8077-3c66d854e095",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_questions = [\"Who is the Dendro Archon?\"]#, \"Where does Kirara works?\", \"Where is Kaeya from?\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc120db-5f5c-4285-b159-4719a6c601ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for q in test_questions:\n",
    "    print(\"My Answer is: {}\".format(ask_a_question(q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9ed0a7-8522-4266-8f49-3d30f57f21cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ask_a_question(\"Where does Kirara works?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1370165-26dd-4019-b63f-137bd0d04676",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ask_a_question(\"What does she wears around her waist?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cd8ac0-682d-4d60-bc36-543c42e1a0b0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ask_a_question(\"Whats her alternative feline form?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0948fbc-8e72-42d6-9401-36c5005eb39d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
