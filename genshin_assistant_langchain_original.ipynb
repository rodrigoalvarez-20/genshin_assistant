{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd54ddc-93a7-4dd1-9e5b-cf17c889ee60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings, HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import ElasticVectorSearch\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import PromptTemplate, HuggingFaceHub, LLMChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, pipeline, AutoModelForSeq2SeqLM\n",
    "from langchain.document_loaders import TextLoader\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71368539-631f-4ae8-a8f8-cb11a989a98d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HF_SENTENCE_TRANSFORMER_MODEL = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "ELASTIC_URL = \"http://localhost:9200/\"\n",
    "ELASTIC_INDEX = \"genshinpedia_small\"\n",
    "DB_FILES = \"en_datasets\"\n",
    "CACHE_DIR = \"./cache\"\n",
    "T2T_MODEL = \"google/flan-t5-base\" # Text2Text\n",
    "ST_SIM_MODEL = \"hkunlp/instructor-base\" #Sentence Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=ST_SIM_MODEL, model_kwargs={\"device\": \"cuda\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62559adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_db = ElasticVectorSearch(embedding=instructor_embeddings, elasticsearch_url=ELASTIC_URL, index_name=ELASTIC_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845167fd-c55a-4173-abcb-40ebe85d842d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def setup_embeddings():\n",
    "    # Huggingface embedding setup\n",
    "    print(\">> Prep. Huggingface embedding setup\")\n",
    "    return HuggingFaceEmbeddings(model_name=HF_SENTENCE_TRANSFORMER_MODEL)\n",
    "hf_embeddings = setup_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f501a10-1488-44f8-9644-49a585dd1675",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "elastic_db = ElasticVectorSearch(embedding=hf_embeddings, elasticsearch_url=ELASTIC_URL, index_name=ELASTIC_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b78991-2afa-4290-97f2-4753e5fd0421",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cargar los archivos a la DB\n",
    "# Segun yo, esto solo se hace cuando no existen datos en nuestro indice\n",
    "list_of_docs = []\n",
    "for file in os.listdir(DB_FILES):\n",
    "    file_path = DB_FILES + \"/\" + file\n",
    "    if not os.path.isfile(file_path):\n",
    "        continue\n",
    "    loader = TextLoader(file_path)\n",
    "    documents = loader.load()\n",
    "    text_splitter = CharacterTextSplitter(\"\\n\", chunk_size=1000, chunk_overlap=0)\n",
    "    docs = text_splitter.split_documents(documents)\n",
    "    #list_of_docs.append(docs)\n",
    "    elastic_db.add_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb904aaf-19e3-4216-ab80-a2281357fb77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d1b50c-1993-454e-aacc-b72b0146e243",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "elastic_db = ElasticVectorSearch(embedding=hf_embeddings, elasticsearch_url=ELASTIC_URL, index_name=ELASTIC_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263e1d0a-4005-499e-b863-39be47a9ce12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "elastic_db.similarity_search(\"Whats the disease of Collei\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ea4029-a0f1-4533-aa23-724389a206a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creacion del modelo para generacion de texto\n",
    "def getFlanModel():\n",
    "    print(f\">> Prep. Get {T2T_MODEL} ready to go\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(T2T_MODEL) \n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(T2T_MODEL, cache_dir=CACHE_DIR) \n",
    "    pipe = pipeline(\n",
    "        \"text2text-generation\",\n",
    "        model=model, \n",
    "        tokenizer=tokenizer, \n",
    "        max_length=100\n",
    "    )\n",
    "    llm = HuggingFacePipeline(pipeline=pipe)\n",
    "    return llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "d2d91045-be62-40bc-adcb-41efd3d0d648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ORIGINAL_PROMPT = \"\"\"\n",
    "I am a helpful AI that answers questions. When I don't know the answer I say I don't know. \n",
    "I know context: {context} when asked: {question} my response using only information in the context is: \n",
    "\"\"\"\n",
    "TUNED_PROMPT = \"\"\"\n",
    "I am a helpful AI that answers questions providing details from the context in my answer. When I don't know the answer I say \"I don't know\" without the quotes.\n",
    "I know the context: {context} when user ask me the {question}. My detailed response is:\n",
    "\"\"\"\n",
    "#using only the information in the context \n",
    "CHATBOT_PROMPT = \"\"\"\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "860cefa5-cce9-42b2-b56a-c4ed4a530b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_the_llm():\n",
    "    prompt_informed = PromptTemplate(template=TUNED_PROMPT, input_variables=[\"context\", \"question\"])\n",
    "    llm = getFlanModel()\n",
    "    return LLMChain(prompt=prompt_informed, llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d637fd89-32b9-47b0-81e0-4dada83725fa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Prep. Get google/flan-t5-base ready to go\n"
     ]
    }
   ],
   "source": [
    "llm_chain_informed= make_the_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "efb68068-073d-4034-9d42-ff5d6f77861e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ask_a_question(question):\n",
    "    similar_docs = elastic_db.similarity_search(question)\n",
    "    print(f'The most relevant passage: \\n\\t{similar_docs[0].page_content}')\n",
    "\n",
    "    ## Ask Local LLM context informed prompt\n",
    "    informed_context= similar_docs[0].page_content\n",
    "    informed_response = llm_chain_informed.run(context=informed_context,question=question)\n",
    "    \n",
    "    return informed_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b8c43c7d-278b-44f9-b984-45f5b27180c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_questions = [\"What is Layla studying?\", \"Where does Kirara works?\", \"Where is Kaeya from?\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4c0a7b96-b874-4d74-a799-374cbabfaee7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most relevant passage: \n",
      "\tShe has been called the Sleepwalking Eccentric, the Human Calculator, and even the Heaven-Sent Thesis by those who know her.\n",
      "As the days go by, her titles only seem to grow in number.\n",
      "Friendship Lv. 2\n",
      "There are two kinds of people in the halls of Akademiya:\n",
      "The first holds themselves with an air of calmness and mastery. Be it experimentation or dissertation, this type of person always makes whatever they're doing look easy.\n",
      "The other kind of person wears their woes on their faces. Sighs spill from their lips as mournful notes while they clutch their tools, looking lost. Intermittently, they will jot something down before slashing it out, battling themselves all the way.\n",
      "Layla belongs to the latter category.\n",
      "Being poor of health and bereft of sleep is not uncommon among researchers, but Layla takes it to a whole other level. The bags of exhaustion hanging beneath her eyes and weariness burned across her features make it impossible for her to hide the stress gnawing at her.\n",
      "My Answer is: I don't know\n",
      "The most relevant passage: \n",
      "\tAround her waist, Kirara wears a stylized black belt consisting of a long piece of black fabric held together with numerous bows of varying colors with a dangling ornament pinned to it and a small blue cape decorated with flowers. Under all of this, she wears a pleated blue skirt lined with gold and a set of black leg warmers.\n",
      "As with many other youkai, Kirara has an alternate feline form, though she does not use it as often as it attracts too much attention.\n",
      "Official Introduction\n",
      "An excess of speed and an assurance of client satisfaction\n",
      "Komaniya Express, the famous delivery company in Inazuma, has a very special employee working under them. At a glance, she resembles an adorably dressed teenage girl with two tails swaying behind her. Though she treats each of her customers with kindness and generosity, secretly she sometimes takes to running quietly across rooftops to ensure none of her deliveries arrive late...\n",
      "My Answer is: Komaniya Express\n",
      "The most relevant passage: \n",
      "\tKaeya uses the tall male model. He has a tanned complexion and navy-blue hair with streaks of lighter blue, accompanied by a waist-length lock of hair that begins at the base of his scalp on the back of his head at the left. His visible eye is periwinkle with a diamond-shaped pupil that is shared with other characters known to be from Khaenri'ah. Over his right eye, he wears a gold-trimmed black eyepatch that is mostly covered by his bangs. Kaeya has not been seen without his eyepatch, but his right eye, which is functional, is implied to have a scar over it due to being wounded by Diluc during their battle after Crepus' death.45\n",
      "My Answer is: Khaenri'ah.\n"
     ]
    }
   ],
   "source": [
    "for q in test_questions:\n",
    "    print(\"My Answer is: {}\".format(ask_a_question(q)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0df5a0-0876-49b0-b2c4-1b71199cc0dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
