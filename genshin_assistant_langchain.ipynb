{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd54ddc-93a7-4dd1-9e5b-cf17c889ee60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings, HuggingFaceInstructEmbeddings\n",
    "from langchain.vectorstores import ElasticVectorSearch\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import ConversationChain, RetrievalQA, ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.schema import SystemMessage\n",
    "from langchain.agents import Tool\n",
    "from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, MessagesPlaceholder\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM,  pipeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71368539-631f-4ae8-a8f8-cb11a989a98d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "HF_SENTENCE_TRANSFORMER_MODEL = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "ELASTIC_URL = \"http://localhost:9200/\"\n",
    "MONGO_URL = \"http://localhost:27017/\"\n",
    "ELASTIC_INDEX = \"genshinpedia_small\"\n",
    "DB_FILES = \"en_datasets\"\n",
    "CACHE_DIR = \"./cache\"\n",
    "T2T_MODEL = \"google/flan-t5-base\" # Text2Text\n",
    "#ST_SIM_MODEL = \"hkunlp/instructor-base\" #Sentence Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7b9cdb",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sección de DB Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f286d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instructor_embeddings = HuggingFaceInstructEmbeddings(model_name=HF_SENTENCE_TRANSFORMER_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62559adb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "elastic_db = ElasticVectorSearch(embedding=instructor_embeddings, elasticsearch_url=ELASTIC_URL, index_name=ELASTIC_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6744f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "db_retriever = elastic_db.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eab6b7d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Sección del modelo base para T2T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cf67a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(T2T_MODEL) \n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(T2T_MODEL, cache_dir=CACHE_DIR) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93e7ab6-9088-47ae-a1b7-29bc567ccefb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipe = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=model, \n",
    "    tokenizer=tokenizer, \n",
    "    max_length=1000,\n",
    "    temperature=0.3,\n",
    "    repetition_penalty=1.15\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d91045-be62-40bc-adcb-41efd3d0d648",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ORIGINAL_PROMPT = \"\"\"\n",
    "I am a helpful AI that answers questions. When I don't know the answer I say I don't know. \n",
    "I know context: {context} when asked: {question} my response using only information in the context is: \n",
    "\"\"\"\n",
    "TUNED_PROMPT = \"\"\"\n",
    "I am a helpful AI that answers questions providing details from the context in my answer. When I don't know the answer I say \"I don't know\" without the quotes.\n",
    "I know the context: {context} when user ask me the {question}. My detailed response is:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b98583f-3059-47f9-bf3b-5ac58c92960e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Seccion de QA Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e8177a-0e62-457f-b376-a0fa5823ee5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, \n",
    "                                       chain_type=\"stuff\", \n",
    "                                       retriever=db_retriever, \n",
    "                                       verbose=True,\n",
    "                                       return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2efdb9d-46b6-468f-ac72-5e85517803f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain(\"Where does Hu Tao works?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab4077f-ef9f-40a7-9bae-23fbf361d194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "qa_chain(\"What does she do at there?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56d859d-a553-4ff8-ba18-8aa4faebe1be",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Creacion de una Tool para el buscador de GI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf995d3-cf09-4474-af1d-3ff4c9f56891",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "genshin_tool = Tool(\n",
    "    name=\"Genshinpedia\",\n",
    "    func= qa_chain.run,\n",
    "    description=\"Useful for when you need to answer questions about Genshin Impact characters\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e5d29d5-8202-4f79-99f9-c7bdd18c2bb1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Intento de Conversacion (Memoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2ee312-4735-4f78-b0ab-2ceae2085213",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\", \n",
    "    #output_key=\"answer\",\n",
    "    return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad28413-75c2-4915-be3c-261266a428a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "memory_blocks = []\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm, \n",
    "    retriever=db_retriever,\n",
    "    memory=memory,\n",
    "    condense_question_prompt=TEST_PROMPT,\n",
    "    #combine_docs_chain_kwargs={\"prompt\": TEST_PROMPT},\n",
    "    return_source_documents=True,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afbe4c66-597c-4a05-9eb0-a68a821ebe05",
   "metadata": {},
   "source": [
    "### Intento de Agente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffeb024-251b-4d47-9b15-44700742d3bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tools = [genshin_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0fcf786-6f68-4105-8ebe-c2c5e13ecf9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#INSTRUCTOR_MODEL = \"tiiuae/falcon-7b-instruct\"\n",
    "INSTRUCTOR_MODEL = \"syzymon/long_llama_3b_instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4135a7a-5277-40ff-a3e7-b51f429ce107",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ralvarez22/anaconda3/lib/python3.11/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ralvarez22/anaconda3/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
     ]
    }
   ],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "from transformers import LlamaTokenizer, AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6829595-075d-4e5c-8663-81b84196deea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "quantization_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7acd203-0110-4ca2-8456-ff5e93bf1e71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_4bit = AutoModelForCausalLM.from_pretrained(\n",
    "    INSTRUCTOR_MODEL, \n",
    "    #device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    torch_dtype=torch.float32\n",
    "    #offload_folder=\"./offloads\",\n",
    "    #quantization_config=quantization_config,\n",
    ")\n",
    "\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer = LlamaTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c326187-f94b-4e37-bb01-951fb867c43d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.version.cuda)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3f347f-5e4f-4d33-8533-62f4789e52d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
